{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, pickle, argparse\n",
    "from random import shuffle\n",
    "import pandas as pd\n",
    "from utils import *\n",
    "#try:\n",
    "#    from FPMC_numba import FPMC\n",
    "#except ImportError:\n",
    "#    from FPMC import FPMC\n",
    "from FPMC import FPMC\n",
    "# numba版本的应该更快，但是暂时还没调好，先用普通版本的\n",
    "\n",
    "cwd = os.path.dirname(os.path.realpath(__file__))\n",
    "\n",
    "\n",
    "allowed_trans = {}\n",
    "\n",
    "n_road = 38026\n",
    "\n",
    "df = pd.read_csv(cwd + '/../database/data/rel.csv')\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    origin_id = int(row['origin_id'])\n",
    "    destination_id = int(row['destination_id'])\n",
    "\n",
    "    if origin_id not in allowed_trans:\n",
    "        allowed_trans[origin_id] = [origin_id]\n",
    "    if destination_id != origin_id and destination_id not in allowed_trans[origin_id]:\n",
    "        allowed_trans[origin_id].append(destination_id)\n",
    "    \n",
    "# 这是为了防止之后出现一些空数组\n",
    "for i in range(n_road + 1):\n",
    "    if i not in allowed_trans:\n",
    "        allowed_trans[i] = [i]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('input_dir', help='The directory of input', type=str)\n",
    "    parser.add_argument('-e', '--n_epoch', help='# of epoch', type=int, default=15)\n",
    "    parser.add_argument('--n_neg', help='# of neg samples', type=int, default=15)\n",
    "    parser.add_argument('-n', '--n_factor', help='dimension of factorization', type=int, default=32)\n",
    "    parser.add_argument('-l', '--learn_rate', help='learning rate', type=float, default=0.01)\n",
    "    parser.add_argument('-r', '--regular', help='regularization', type=float, default=0.001)\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    f_dir = args.input_dir\n",
    "\n",
    "    data_list, user_set, item_set = load_data_from_dir(f_dir)\n",
    "    shuffle(data_list)\n",
    "\n",
    "    train_ratio = 0.8\n",
    "    split_idx = int(len(data_list) * train_ratio)\n",
    "    tr_data = data_list[:split_idx]\n",
    "    # print(tr_data)\n",
    "    te_data = data_list[split_idx:]\n",
    "\n",
    "    fpmc = FPMC(n_user=max(user_set)+1, n_item=max(item_set)+1, \n",
    "                n_factor=args.n_factor, learn_rate=args.learn_rate, regular=args.regular, allowed_trans=allowed_trans)\n",
    "    fpmc.user_set = user_set\n",
    "    fpmc.item_set = item_set\n",
    "    fpmc.init_model()\n",
    "\n",
    "    acc, mrr = fpmc.learnSBPR_FPMC(tr_data, te_data, n_epoch=args.n_epoch, \n",
    "                                   neg_batch_size=args.n_neg, eval_per_epoch=False)\n",
    "\n",
    "    print (\"Accuracy:%.2f MRR:%.2f\" % (acc, mrr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpmc.dump(fpmcObj=fpmc,fname=cwd+'/model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from utils import load_jump_task_from\n",
    "from FPMC import FPMC\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "cwd = os.path.dirname(os.path.realpath(__file__))\n",
    "\n",
    "data_list = load_jump_task_from(cwd + '/data/jump.txt')\n",
    "\n",
    "model = FPMC.load(cwd + '/model.pkl')\n",
    "\n",
    "\n",
    "allowed_trans = {}\n",
    "\n",
    "n_road = 38026\n",
    "\n",
    "df = pd.read_csv(cwd + '/../database/data/rel.csv')\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    origin_id = int(row['origin_id'])\n",
    "    destination_id = int(row['destination_id'])\n",
    "    if origin_id not in allowed_trans:\n",
    "        allowed_trans[origin_id] = [origin_id]\n",
    "    if destination_id != origin_id and destination_id not in allowed_trans[origin_id]:\n",
    "        allowed_trans[origin_id].append(destination_id)\n",
    "for i in range(n_road + 1):\n",
    "    if i not in allowed_trans:\n",
    "        allowed_trans[i] = [i]\n",
    "        \n",
    "num = len(data_list) # 预测的数量默认为data_list的总数量，想要少点的话可以自己改\n",
    "\n",
    "for i in range(num + 1):\n",
    "    l = data_list[i]\n",
    "    u, i, b_tm1 = l\n",
    "    current_status = b_tm1[-1]\n",
    "    res = -np.inf\n",
    "    best_path = []\n",
    "    for best_choice in allowed_trans[current_status]:\n",
    "        road = b_tm1\n",
    "        road.append(best_choice)\n",
    "        r = model.compute_x_batch(u, best_path)\n",
    "        if r > res:\n",
    "            best_path = road\n",
    "            res = r\n",
    "    print('最佳预测为:', best_path[-1])\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
